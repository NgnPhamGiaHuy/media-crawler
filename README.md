# ğŸŒ Media Crawler

![Python](https://img.shields.io/badge/python-3.7+-blue.svg)
![Flask](https://img.shields.io/badge/Flask-2.0+-green.svg)
![License](https://img.shields.io/badge/license-MIT-green)

## ğŸ“ Description

Media Crawler is a powerful web application that automates the discovery and downloading of media files (images, videos, and audio) from any website. It uses asynchronous crawling techniques to efficiently navigate through web pages, extract media URLs, and download them into a structured cache system. Perfect for content creators, researchers, and developers who need to extract media assets from websites.

The application features a clean web interface for URL submission and results viewing, with a robust backend API that handles the crawling, downloading, and media processing.

## âœ¨ Features

- Crawls websites to discover and download media files (images, videos, audio)
- Supports customizable crawl depth for single-page or multi-page extraction
- Generates thumbnails for visual preview of discovered media
- Respects robots.txt directives for ethical crawling
- Maintains session-based caching for efficient storage and retrieval
- Provides a clean web interface for easy interaction
- Offers a comprehensive API for programmatic access
- Handles concurrent downloads for optimal performance
- Auto-cleanup of expired cache sessions

## âš™ï¸ Installation

```bash
# Clone the repository
git clone https://github.com/NgnPhamGiaHuy/media-crawler.git
cd media-crawler

# Create and activate virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Create .env file (optional)
cp env.example .env  # Then edit the .env file as needed
```

## ğŸš€ Usage

```bash
# Run the application
python app.py

# Access the web interface
# Open http://localhost:5050 in your browser
```

### API Usage

```bash
# Example API call to crawl a URL
curl -X POST http://localhost:5050/api/crawl \
  -H "Content-Type: application/json" \
  -d '{"url": "https://example.com", "depth": 1}'
```

## ğŸ”§ Configuration

Create a `.env` file in the root directory with the following variables (or set them as environment variables):

```
DEBUG=False
SECRET_KEY=your_secret_key_here
CACHE_DIR=@cachefolder
CACHE_EXPIRY=3600
MAX_CRAWL_DEPTH=1
MAX_CONCURRENT_REQUESTS=5
REQUEST_TIMEOUT=30
RESPECT_ROBOTS_TXT=True
USER_AGENT=MediaCrawler/1.0
HOST=0.0.0.0
PORT=5050
```

## ğŸ—‚ï¸ Folder Structure

```
â”œâ”€â”€ app/                  # Application code
â”‚   â”œâ”€â”€ config/           # Configuration settings
â”‚   â”œâ”€â”€ models/           # Data models
â”‚   â”œâ”€â”€ routes/           # API and web routes
â”‚   â”œâ”€â”€ services/         # Core services (crawler, cache, media)
â”‚   â”‚   â”œâ”€â”€ cache/        # Cache management
â”‚   â”‚   â”œâ”€â”€ crawler/      # Web crawling engine
â”‚   â”‚   â””â”€â”€ media/        # Media processing
â”‚   â”œâ”€â”€ static/           # Static files (JS, CSS)
â”‚   â”œâ”€â”€ templates/        # HTML templates
â”‚   â””â”€â”€ utils/            # Utility functions
â”œâ”€â”€ venv/                 # Virtual environment
â”œâ”€â”€ app.py                # Application entry point
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ README.md             # Project documentation
```

## ğŸ¤ Contributing

```bash
# Fork the repository
# Clone your fork
git clone https://github.com/NgnPhamGiaHuy/media-crawler.git

# Create a feature branch
git checkout -b feature/amazing-feature

# Commit your changes
git commit -m "Add amazing feature"

# Push to the branch
git push origin feature/amazing-feature

# Open a Pull Request
```

## ğŸ“„ License

Licensed under the MIT License. See [LICENSE](./LICENSE) for more information.

## ğŸ‘¤ Author

**NgnPhamGiaHuy**

[![GitHub](https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white)](https://github.com/NgnPhamGiaHuy)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://linkedin.com/in/nguyenphamgiahuy)

## ğŸ™ Acknowledgements

- Built with Flask and Beautiful Soup
- Asynchronous operations powered by aiohttp
- Interface styled with Bootstrap
- Icons by Font Awesome 